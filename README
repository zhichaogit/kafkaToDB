# kafkaCDC 
usage: Consumer Server

 -b,--broker <arg>      bootstrap.servers setting, ex: <node>:9092,default: "localhost:9092"
    --bigendian         the data format is big endian, default: little endian
 -c,--commit <arg>      num message per Kakfa synch/pull, default: 5000
 -d,--dbip <arg>        database server ip, default: "localhost"
    --dbport <arg>      database server port, default: 23400
    --dbpw <arg>        database server password, default: zz
    --dbuser <arg>      database server user, default: db__root
    --delim <arg>       field delimiter, default: ','(comma)
 -e,--encode <arg>      character encoding of data, default: "utf8"
 -f,--format <arg>      format of data, support "Unicom"  "HongQuan"  "Json" "Protobuf" and "user-defined" , default: ""
    --full              pull data from beginning, default: false
 -g,--group <arg>       group for this consumer, default: 0
 -h,--help              show help information
    --interval <arg>    the print state time interval, the unit is second,default: 10s
    --keepalive <arg>   check database keepalive, default is false
    --key <arg>         key deserializer, default is:
                        org.apache.kafka.common.serialization.StringDeserializer
    --kafkauser <arg>   kafka user name , default: ""
    --kafkapw   <arg>   kafka password , default: ""
 -p,--partition <arg>   partition number to process message, one thread only process
                        the data from one partition,default: 16. the format: "id [, id] ...", id should be: "id-id". 
                        example:
                        a. -p "1,4-5,8" : means process the partition 1,4,5 and 8
                        b. -p 4 : means process the partition 0,1,2 and 3 
                        c. -p "2-2" : means process the partition 2
 -s,--schema <arg>      default database schema, use the schema from data without this option,
                        you should write like this [schemaName] if schemaName is lowerCase. default:null
    --skip              skip all errors of data, default: false
    --sto <arg>         kafka poll time-out limit, default: 60s
 -t,--topic <arg>       REQUIRED. topic of subscription
    --table <arg>       table name, default: null,you should write like this [tablename]  if tablename is lowerCase
    --tenant <arg>      tanent user name, default: null
 -v,--version           print the version of KafkaCDC
    --value <arg>       value deserializer, default is:
                        org.apache.kafka.common.serialization.StringDeserializer
 -z,--zook <arg>        zookeeper connection list, ex:<node>:port[/kafka],...
    --zkto <arg>        zookeeper time-out limit, default: 10s
    

Must create the schema and tables first of all.

The use example for KafkaCDC:
1. normal
# ./KafkaCDC-server.sh -p 1 -b localhost:9092 -d localhost -g 1 -s SEABASE --table tab -t test --full --dbuser trafodion --dbpw traf123
# ./KafkaCDC-server.sh -p 1 -b localhost:9092 -d localhost -g 1 -s SEABASE --table tab -t test --full --sto 20 --interval 10 --sto 20  --dbuser trafodion --dbpw traf123 -c 500 -delim "|"

2. HongQuan
# ./KafkaCDC-server.sh -p 1 -b localhost:9092 -d localhost -g 1 -s SEABASE --table tab -t g_ad --full --dbuser trafodion --dbpw traf123 -f HongQuan -s kafkaCDC --table hqTable  --sto 20 --interval 10 --zkto 20 --key org.apache.kafka.common.serialization.LongDeserializer --value org.apache.kafka.common.serialization.ByteArrayDeserializer

3. Unicom
# ./KafkaCDC-server.sh -p 1 -b localhost:9092 -d localhost -g 1 -f Unicom  -t test
# ./KafkaCDC-server.sh -p 1 -b localhost:9092 -d localhost -g 1 -f Unicom --full --dbuser trafodion --dbpw traf123 -t test
# ./KafkaCDC-server.sh -p 1 -b localhost:9092 -d localhost -g 1 -f Unicom --full --dbuser trafodion --dbpw traf123 -s SEABASE  -t test
# ./KafkaCDC-server.sh -p 1 -b localhost:9092 -d localhost -g 1 -f Unicom --full --dbuser trafodion --dbpw traf123 -s SEABASE --table tab -t test --sto 20 --interval 10 --zkto 20 --dbip localhost -c 500

4.Json
# ./KafkaCDC-server.sh -p 1 -b localhost:9092 -d localhost -g 1 -f Json --full --dbuser trafodion --dbpw traf123 -s [schemaname] -t testTopic --sto 20 --interval 10 -c 500
